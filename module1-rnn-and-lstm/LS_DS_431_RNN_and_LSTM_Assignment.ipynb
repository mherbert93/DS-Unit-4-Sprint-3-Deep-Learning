{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
    "\n",
    "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
    "\n",
    "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
    "\n",
    "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
    "\n",
    "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
    "\n",
    "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
    "\n",
    "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
    "\n",
    "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import requests\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/files/100/100-0.txt\"\n",
    "\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.encoding = r.apparent_encoding\n",
    "\n",
    "data = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\nProject Gutenberg’s The Complete Works of William Shakespeare, by William\\r\\nShakespeare\\r\\n\\r\\nThis eBo'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split('\\r\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skip the Table of Contents\n",
    "data = data[135:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = [l.strip() for l in data[44:130:2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALL’S WELL THAT ENDS WELL',\n",
       " 'THE TRAGEDY OF ANTONY AND CLEOPATRA',\n",
       " 'AS YOU LIKE IT',\n",
       " 'THE COMEDY OF ERRORS',\n",
       " 'THE TRAGEDY OF CORIOLANUS',\n",
       " 'CYMBELINE',\n",
       " 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK',\n",
       " 'THE FIRST PART OF KING HENRY THE FOURTH',\n",
       " 'THE SECOND PART OF KING HENRY THE FOURTH',\n",
       " 'THE LIFE OF KING HENRY THE FIFTH',\n",
       " 'THE FIRST PART OF HENRY THE SIXTH',\n",
       " 'THE SECOND PART OF KING HENRY THE SIXTH',\n",
       " 'THE THIRD PART OF KING HENRY THE SIXTH',\n",
       " 'KING HENRY THE EIGHTH',\n",
       " 'KING JOHN',\n",
       " 'THE TRAGEDY OF JULIUS CAESAR',\n",
       " 'THE TRAGEDY OF KING LEAR',\n",
       " 'LOVE’S LABOUR’S LOST',\n",
       " 'THE TRAGEDY OF MACBETH',\n",
       " 'MEASURE FOR MEASURE',\n",
       " 'THE MERCHANT OF VENICE',\n",
       " 'THE MERRY WIVES OF WINDSOR',\n",
       " 'A MIDSUMMER NIGHT’S DREAM',\n",
       " 'MUCH ADO ABOUT NOTHING',\n",
       " 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE',\n",
       " 'PERICLES, PRINCE OF TYRE',\n",
       " 'KING RICHARD THE SECOND',\n",
       " 'KING RICHARD THE THIRD',\n",
       " 'THE TRAGEDY OF ROMEO AND JULIET',\n",
       " 'THE TAMING OF THE SHREW',\n",
       " 'THE TEMPEST',\n",
       " 'THE LIFE OF TIMON OF ATHENS',\n",
       " 'THE TRAGEDY OF TITUS ANDRONICUS',\n",
       " 'THE HISTORY OF TROILUS AND CRESSIDA',\n",
       " 'TWELFTH NIGHT; OR, WHAT YOU WILL',\n",
       " 'THE TWO GENTLEMEN OF VERONA',\n",
       " 'THE TWO NOBLE KINSMEN',\n",
       " 'THE WINTER’S TALE',\n",
       " 'A LOVER’S COMPLAINT',\n",
       " 'THE PASSIONATE PILGRIM',\n",
       " 'THE PHOENIX AND THE TURTLE',\n",
       " 'THE RAPE OF LUCRECE',\n",
       " 'VENUS AND ADONIS']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = {id_:{'title':title, 'start':-99} for id_,title in enumerate(toc)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing Titles\n",
    "locations[9]['title'] = 'THE LIFE OF KING HENRY V'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "43",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-15-b17799167a04>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0mt\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoc\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 14\u001B[0;31m         \u001B[0mend\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlocations\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'start'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     15\u001B[0m         \u001B[0mlocations\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'end'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mend\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m         \u001B[0mt\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 43"
     ]
    }
   ],
   "source": [
    "# Start \n",
    "for e,i in enumerate(data):\n",
    "    for t,title in enumerate(toc):\n",
    "        if title in i:\n",
    "            locations[t].update({'start':e})\n",
    "            \n",
    "# End            \n",
    "for title in toc:\n",
    "    \n",
    "    t = 0\n",
    "    \n",
    "    while t < len(toc):\n",
    "        print(t)\n",
    "        end = locations[t+1]['start'] - 1\n",
    "        locations[t]['end'] = end\n",
    "        t += 1\n",
    "\n",
    "    # Last One\n",
    "    locations[t]['end'] = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'THE LIFE OF KING HENRY V', 'start': -99, 'end': 47572}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'title': 'ALL’S WELL THAT ENDS WELL', 'start': 2777, 'end': 7738},\n",
       " 1: {'title': 'THE TRAGEDY OF ANTONY AND CLEOPATRA',\n",
       "  'start': 7739,\n",
       "  'end': 11840},\n",
       " 2: {'title': 'AS YOU LIKE IT', 'start': 11841, 'end': 14631},\n",
       " 3: {'title': 'THE COMEDY OF ERRORS', 'start': 14632, 'end': 17832},\n",
       " 4: {'title': 'THE TRAGEDY OF CORIOLANUS', 'start': 17833, 'end': 27806},\n",
       " 5: {'title': 'CYMBELINE', 'start': 27807, 'end': 27824},\n",
       " 6: {'title': 'THE TRAGEDY OF HAMLET, PRINCE OF DENMARK',\n",
       "  'start': 27825,\n",
       "  'end': 34511},\n",
       " 7: {'title': 'THE FIRST PART OF KING HENRY THE FOURTH',\n",
       "  'start': 34512,\n",
       "  'end': 39227},\n",
       " 8: {'title': 'THE SECOND PART OF KING HENRY THE FOURTH',\n",
       "  'start': 39228,\n",
       "  'end': -100},\n",
       " 9: {'title': 'THE LIFE OF KING HENRY V', 'start': -99, 'end': 47572},\n",
       " 10: {'title': 'THE FIRST PART OF HENRY THE SIXTH',\n",
       "  'start': 47573,\n",
       "  'end': 50843},\n",
       " 11: {'title': 'THE SECOND PART OF KING HENRY THE SIXTH',\n",
       "  'start': 50844,\n",
       "  'end': 54331},\n",
       " 12: {'title': 'THE THIRD PART OF KING HENRY THE SIXTH',\n",
       "  'start': 54332,\n",
       "  'end': 57717},\n",
       " 13: {'title': 'KING HENRY THE EIGHTH', 'start': 57718, 'end': 64170},\n",
       " 14: {'title': 'KING JOHN', 'start': 64171, 'end': 64243},\n",
       " 15: {'title': 'THE TRAGEDY OF JULIUS CAESAR', 'start': 64244, 'end': 68887},\n",
       " 16: {'title': 'THE TRAGEDY OF KING LEAR', 'start': 68888, 'end': 74923},\n",
       " 17: {'title': 'LOVE’S LABOUR’S LOST', 'start': 74924, 'end': -100},\n",
       " 18: {'title': 'THE TRAGEDY OF MACBETH', 'start': -99, 'end': 81987},\n",
       " 19: {'title': 'MEASURE FOR MEASURE', 'start': 81988, 'end': 84987},\n",
       " 20: {'title': 'THE MERCHANT OF VENICE', 'start': 84988, 'end': 89155},\n",
       " 21: {'title': 'THE MERRY WIVES OF WINDSOR', 'start': 89156, 'end': 92114},\n",
       " 22: {'title': 'A MIDSUMMER NIGHT’S DREAM', 'start': 92115, 'end': 95574},\n",
       " 23: {'title': 'MUCH ADO ABOUT NOTHING', 'start': 95575, 'end': -100},\n",
       " 24: {'title': 'THE TRAGEDY OF OTHELLO, MOOR OF VENICE',\n",
       "  'start': -99,\n",
       "  'end': 107556},\n",
       " 25: {'title': 'PERICLES, PRINCE OF TYRE', 'start': 107557, 'end': 111699},\n",
       " 26: {'title': 'KING RICHARD THE SECOND', 'start': 111700, 'end': 114792},\n",
       " 27: {'title': 'KING RICHARD THE THIRD', 'start': 114793, 'end': 119200},\n",
       " 28: {'title': 'THE TRAGEDY OF ROMEO AND JULIET',\n",
       "  'start': 119201,\n",
       "  'end': 124456},\n",
       " 29: {'title': 'THE TAMING OF THE SHREW', 'start': 124457, 'end': 129330},\n",
       " 30: {'title': 'THE TEMPEST', 'start': 129331, 'end': 133153},\n",
       " 31: {'title': 'THE LIFE OF TIMON OF ATHENS', 'start': 133154, 'end': 135869},\n",
       " 32: {'title': 'THE TRAGEDY OF TITUS ANDRONICUS',\n",
       "  'start': 135870,\n",
       "  'end': 138745},\n",
       " 33: {'title': 'THE HISTORY OF TROILUS AND CRESSIDA',\n",
       "  'start': 138746,\n",
       "  'end': -100},\n",
       " 34: {'title': 'TWELFTH NIGHT; OR, WHAT YOU WILL',\n",
       "  'start': -99,\n",
       "  'end': 149391},\n",
       " 35: {'title': 'THE TWO GENTLEMEN OF VERONA', 'start': 149392, 'end': 151803},\n",
       " 36: {'title': 'THE TWO NOBLE KINSMEN', 'start': 151804, 'end': 156991},\n",
       " 37: {'title': 'THE WINTER’S TALE', 'start': 156992, 'end': 162006},\n",
       " 38: {'title': 'A LOVER’S COMPLAINT', 'start': 162007, 'end': 162389},\n",
       " 39: {'title': 'THE PASSIONATE PILGRIM', 'start': 162390, 'end': 162629},\n",
       " 40: {'title': 'THE PHOENIX AND THE TURTLE', 'start': 162630, 'end': 162723},\n",
       " 41: {'title': 'THE RAPE OF LUCRECE', 'start': 162724, 'end': 164942},\n",
       " 42: {'title': 'VENUS AND ADONIS', 'start': 164943}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2777\n"
     ]
    }
   ],
   "source": [
    "for e, i in enumerate(data):\n",
    "    \n",
    "    if \"ALL’S WELL THAT ENDS WELL\" in i:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE SONNETS'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide b/w plays and sonets\n",
    "sonets = data[:2776]\n",
    "plays = data[2777:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE SONNETS'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_lines(lst_ln):\n",
    "    clean = []\n",
    "    \n",
    "    for ln in lst_ln: \n",
    "        \n",
    "        if len(ln) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            pct = len(ln.strip(' ')) / len(ln)\n",
    "\n",
    "            if pct >= .5:\n",
    "                clean.append(ln.lstrip())\n",
    "\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May Not be Needed\n",
    "#sonets = long_lines(sonets)\n",
    "#plays = long_lines(plays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Encoding\n",
    "\n",
    "This is just a start, and is not complete yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(set(\"\\r\\n\".join(plays).split()))\n",
    "words = [line.split() for line in plays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Encoding\n",
    "\n",
    "Using the technique shown in lecture. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our corpus contains 73 unique characters.\n"
     ]
    }
   ],
   "source": [
    "text = '\\r\\n'.join(sonets)\n",
    "\n",
    "chars = list(set(text))\n",
    "\n",
    "char_int = {c:i for i,c in enumerate(chars)}\n",
    "int_char = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "print(f\"Our corpus contains {len(chars)} unique characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences: 100978\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequence Data\n",
    "\n",
    "maxlen = 150\n",
    "step = 1\n",
    "\n",
    "encoded = [char_int[c] for c in text]\n",
    "\n",
    "sequences = [] # Each element is 40 characters long\n",
    "next_chars = [] # One element for each sequence\n",
    "\n",
    "for i in range(0, len(encoded) - maxlen, step):\n",
    "    sequences.append(encoded[i : i + maxlen])\n",
    "    next_chars.append(encoded[i + maxlen])\n",
    "    \n",
    "print('sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Specify x & y\n",
    "\n",
    "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        x[i,t,char] = 1\n",
    "        \n",
    "    y[i, next_chars[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100978, 150, 73)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars)), dropout=0.2))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 1028)              4531424   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 73)                75117     \n",
      "=================================================================\n",
      "Total params: 4,606,541\n",
      "Trainable params: 4,606,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / 1\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    \n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    generated = ''\n",
    "    \n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence + '\"')\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_int[char]] = 1\n",
    "            \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds)\n",
    "        next_char = int_char[next_index]\n",
    "        \n",
    "        sentence = sentence[1:] + next_char\n",
    "        \n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print()\n",
    "\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80782 samples, validate on 20196 samples\n",
      "Epoch 1/100\n",
      " 2048/80782 [..............................] - ETA: 26:02 - loss: 4.0877\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"Each changing place with that which goes before,\n",
      "In sequent toil all forwards do contend.\n",
      "Nativity once in the main of light,\n",
      "Crawls to maturity, w\"\n",
      "Each changing place with that which goes before,\n",
      "In sequent toil all forwards do contend.\n",
      "Nativity once in the main of light,\n",
      "Crawls to maturity, wcyoObdsGhahotnlrior soGdon\n",
      "diirhma\n",
      "s2flhEA srSosiiGnohr\n",
      " cuish\n",
      "swhothuhgn\n",
      "s8i5hplhsahbhv\n",
      "!hr Phodhho ihrlhnzolhivuoiRr rhf3h\n",
      "izws\n",
      "olhaaonhyloAwisellollhhh,lnOt5htrzhylsTnh criYvl1ehyTsaagrwsFchDbriBo:isnhlnotAtOr.rooslatthh,o,S dsf 5ol ohbrlt?(rtronEhnilr5ghc,svrimash,b, ogBaalOxSgochhwthoif!Rn do5wqcgnn at3krwn.\n",
      "sdssiil,olamrr Tlohg,r\n",
      "yrOhwioe\n",
      "wiwJtlfia3soofvadAytaytc p,mhiGo oyvf rtn5h\n",
      " 2048/80782 [..............................] - ETA: 1:09:39 - loss: 4.0877"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-3fec21fe2220>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m           callbacks=[print_callback, \n\u001B[1;32m      9\u001B[0m                      \u001B[0;31m#EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m                      tensorboard_callback])\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    817\u001B[0m         \u001B[0mmax_queue_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_queue_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    818\u001B[0m         \u001B[0mworkers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mworkers\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 819\u001B[0;31m         use_multiprocessing=use_multiprocessing)\n\u001B[0m\u001B[1;32m    820\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    821\u001B[0m   def evaluate(self,\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001B[0m\n\u001B[1;32m    340\u001B[0m                 \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mModeKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    341\u001B[0m                 \u001B[0mtraining_context\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtraining_context\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 342\u001B[0;31m                 total_epochs=epochs)\n\u001B[0m\u001B[1;32m    343\u001B[0m             \u001B[0mcbks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmake_logs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_logs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining_result\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mModeKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTRAIN\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001B[0m in \u001B[0;36mrun_one_epoch\u001B[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001B[0m\n\u001B[1;32m    126\u001B[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001B[1;32m    127\u001B[0m       \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 128\u001B[0;31m         \u001B[0mbatch_outs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexecution_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    129\u001B[0m       \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mStopIteration\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0merrors\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mOutOfRangeError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    130\u001B[0m         \u001B[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001B[0m in \u001B[0;36mexecution_function\u001B[0;34m(input_fn)\u001B[0m\n\u001B[1;32m     96\u001B[0m     \u001B[0;31m# `numpy` translates Tensors to values in Eager mode.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m     return nest.map_structure(_non_none_constant_value,\n\u001B[0;32m---> 98\u001B[0;31m                               distributed_function(input_fn))\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0mexecution_function\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    566\u001B[0m         \u001B[0mxla_context\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mExit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    567\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 568\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    569\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    570\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mtracing_count\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_tracing_count\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001B[0m in \u001B[0;36m_call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    597\u001B[0m       \u001B[0;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m       \u001B[0;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 599\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    600\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    601\u001B[0m       \u001B[0;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2361\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2362\u001B[0m       \u001B[0mgraph_function\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_define_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2363\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mgraph_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_filtered_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2364\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2365\u001B[0m   \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_filtered_call\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m   1609\u001B[0m          if isinstance(t, (ops.Tensor,\n\u001B[1;32m   1610\u001B[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001B[0;32m-> 1611\u001B[0;31m         self.captured_inputs)\n\u001B[0m\u001B[1;32m   1612\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1613\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_call_flat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcaptured_inputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcancellation_manager\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1690\u001B[0m       \u001B[0;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1691\u001B[0m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0;32m-> 1692\u001B[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0m\u001B[1;32m   1693\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001B[1;32m   1694\u001B[0m         \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    543\u001B[0m               \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m               \u001B[0mattrs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"executor_type\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexecutor_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"config_proto\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconfig\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 545\u001B[0;31m               ctx=ctx)\n\u001B[0m\u001B[1;32m    546\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    547\u001B[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001B[0;32m~/anaconda3/envs/U4-S3-MNA-DS11/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001B[1;32m     60\u001B[0m                                                \u001B[0mop_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mattrs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m                                                num_outputs)\n\u001B[0m\u001B[1;32m     62\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=1024,\n",
    "          validation_split=.2,\n",
    "          epochs=100,\n",
    "          callbacks=[print_callback, \n",
    "                     #EarlyStopping(min_delta=.02, monitor='val_loss', patience=10),\n",
    "                     tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zE4a4O7Bp5x1"
   },
   "source": [
    "# Resources and Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "## Stretch goals:\n",
    "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
    "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
    "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
    "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
    "- Run on bigger, better data\n",
    "\n",
    "## Resources:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
    "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
    "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
    "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
    "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "unit4-sprint2",
   "language": "python",
   "display_name": "Unit4-Sprint2 (Python3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}